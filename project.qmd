---
title: "final project"
format: html
---


```{python}
import pandas as pd
import os

# Directory containing all the files
directory = '/Users/sara/Desktop/Python/final project/Final_project_Group13/Data'

# List of files to process
file_list = [
    "table14full13.xlsx", "table14full14.xlsx", "table14full15.xlsx",
    "table14full16.xlsx", "table14full17.xlsx", "table14full18.xlsx",
    "table14full19.xlsx", "table14full20.xlsx", "table14full21.xlsx",
    "table14full22.xlsx", "table14full23.xlsx"
]

# List to store DataFrames
all_data = []

# List of yellow-highlighted groups
yellow_highlighted_groups = ["White", "Black or African American", "Hispanic or Latino ethnicity"]

# Loop through each file
for file_name in file_list:
    # Extract year from the file name (e.g., "2013" from "table14full13.xlsx")
    year = file_name.replace("table14full", "").replace(".xlsx", "")
    
    # Load the Excel file
    file_path = os.path.join(directory, file_name)
    excel_file = pd.ExcelFile(file_path)
    
    # Use the first sheet name (assuming there's only one sheet per file)
    sheet_name = excel_file.sheet_names[0]
    
    # Load the sheet into a DataFrame
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=5)
    
    # Dynamically rename columns based on the number of columns detected
    column_count = len(df.columns)
    if column_count == 14:
        df.columns = [
            "FIPS_State_Code", "Group_Code", "State", "Group", 
            "Population", "Labor_Force", "Employment_Percentage", 
            "Number_Employed", "Population_Percentage", "Unemployment_Number", 
            "Unemployment_Rate", "Error_Range", "Extra1", "Extra2"
        ]
    elif column_count == 12:
        df.columns = [
            "FIPS_State_Code", "Group_Code", "State", "Group", 
            "Population", "Labor_Force", "Employment_Percentage", 
            "Number_Employed", "Population_Percentage", "Unemployment_Number", 
            "Unemployment_Rate", "Error_Range"
        ]
    else:
        raise ValueError(f"Unexpected number of columns ({column_count}) in file {file_name}")
    
    # Filter for relevant groups
    filtered_data = df[df["Group"].isin(yellow_highlighted_groups)]
    
    # Add year column
    filtered_data["Year"] = year
    
    # Select relevant columns and add to list
    all_data.append(filtered_data[["State", "Group", "Unemployment_Rate", "Year"]])

# Combine all data into a single DataFrame
final_data = pd.concat(all_data, ignore_index=True)

# Save to a new Excel file
output_file = os.path.join(directory, "unemployment_race_filtered_data.xlsx")
final_data.to_excel(output_file, index=False)
```

```{python}
print(final_data.head())
```


### clean unemployment rate by state by year


```{python}
import pandas as pd

# Load the Excel file into a DataFrame
file_path = '/Users/sara/Desktop/Python/final project/Final_project_Group13/Data/State_unemployment_rates.xlsx'

# Read the Excel file
df_unemployment = pd.read_excel(file_path, sheet_name='Sheet1')

# Set "State" as the index for easier manipulation
df_unemployment.set_index("State", inplace=True)

# Transpose the dataset to make months easier to process
df_unemployment = df_unemployment.transpose()

# Convert the index to datetime for filtering
df_unemployment.index = pd.to_datetime(df_unemployment.index)

# Filter for December data and September 2024
df_december = df_unemployment[df_unemployment.index.month == 12]
df_sep_2024 = df_unemployment[(df_unemployment.index.year == 2024) & (df_unemployment.index.month == 9)]

# Convert December index to year for easier understanding
df_december.index = df_december.index.year

# Add September 2024 data to the December dataset with year set as 2024
if not df_sep_2024.empty:
    df_sep_2024.index = [2024]
    df_december = pd.concat([df_december, df_sep_2024])

# Transpose back to make states as columns for final presentation
df_december = df_december.transpose()

# Reset the index and rename the columns
df_december.reset_index(inplace=True)
df_december.rename(columns={"index": "State"}, inplace=True)

# Save the processed data to a new Excel file
output_file = '/Users/sara/Desktop/Python/final project/Final_project_Group13/Data/Filtered_Unemployment_Data.xlsx'
df_december.to_excel(output_file, index=False)

print(f"Filtered unemployment rates (including Sep-24) saved to {output_file}")


```

# Import data
```{python}
import pandas as pd

unemployment_rate = pd.read_excel('./Data/Filtered_Unemployment_Data.xlsx')

min_wage = pd.read_excel('./Data/Min_wage.xlsx')

unemployment_rate_race = pd.read_excel('./Data/unemployment_race_filtered_data.xlsx')
```


```{python}
min_wage_long = min_wage.melt(id_vars=['State'], var_name='Year', value_name='Min_Wage')

min_wage_long['Min_Wage'] = min_wage_long['Min_Wage'].astype(float)

unemployment_rate_long = unemployment_rate.melt(id_vars=['State'], var_name='Year', value_name='Unemployment_Rate')

merged_data = pd.merge(min_wage_long, unemployment_rate_long, on=['State', 'Year'])

# Calculate the year-over-year change in minimum wage
min_wage_long['Min_Wage_Change'] = min_wage_long.groupby('State')['Min_Wage'].diff().ne(0)

# Filter states where the minimum wage changed
states_with_changes = min_wage_long[min_wage_long['Min_Wage_Change']].drop_duplicates(subset='State')

# Get the list of states with minimum wage changes
states_with_changes_list = states_with_changes['State'].tolist()

# Filter the merged data for these states
final_data = merged_data[merged_data['State'].isin(states_with_changes_list)]

import altair as alt

# Create the Altair chart
chart = alt.Chart(final_data).mark_line(point=True).encode(
    x='Year:O',  # x-axis as categorical (ordinal) years
    y='Unemployment_Rate:Q',  # y-axis as quantitative (numerical) unemployment rate
    color='State:N',  # Color by State to differentiate lines
    tooltip=['State', 'Year', 'Unemployment_Rate']  # Add tooltip to show details on hover
).properties(
    title='Unemployment Rate Change for States with Minimum Wage Changes (2014-2024)',
    width=500,
    height=300
)

# Show the chart
chart.show()

```


### TOP 10 varaicne of minimum wage state

```{python}
min_wage_long = min_wage.melt(id_vars=['State'], var_name='Year', value_name='Min_Wage')
unemployment_rate_long = unemployment_rate.melt(id_vars=['State'], var_name='Year', value_name='Unemployment_Rate')

# Merge the dataframes
merged_data = pd.merge(min_wage_long, unemployment_rate_long, on=['State', 'Year'])

# Calculate variance in Min_Wage for each state
state_variance = (
    merged_data.groupby('State')['Min_Wage']
    .var()
    .reset_index()
    .rename(columns={'Min_Wage': 'Variance'})
)

# Get the top 10 states with the highest variance
top_states = state_variance.nlargest(10, 'Variance')['State']

# Filter the merged data for these states
filtered_data = merged_data[merged_data['State'].isin(top_states)]

# Create the Altair chart
chart = alt.Chart(filtered_data).mark_line(point=True).encode(
    x='Year:O',  # x-axis as categorical (ordinal) years
    y='Unemployment_Rate:Q',  # y-axis as quantitative (numerical) unemployment rate
    color='State:N',  # Color by State to differentiate lines
    tooltip=['State', 'Year', 'Unemployment_Rate']  # Add tooltip to show details on hover
).properties(
    title='Unemployment Rate Change for Top 10 States with Highest Variance of minimum wage (2014-2024)',
    width=800,
    height=400
)

# Show the chart
chart.show()
```


```{python}
# Filter the merged data for these states
filtered_data = merged_data[merged_data['State'].isin(top_states)]

chart = alt.Chart(filtered_data).mark_line(point=True).encode(
    x=alt.X('Min_Wage:Q', scale=alt.Scale(zero=False), title='Minimum Wage'),  # x-axis without starting at zero
    y=alt.Y('Unemployment_Rate:Q', scale=alt.Scale(), title='Unemployment Rate'),  # y-axis without starting at zero
    color='State:N',  # Color by State to differentiate lines
    tooltip=['State', 'Year', 'Min_Wage', 'Unemployment_Rate']  # Tooltip for more details
).properties(
    title='Unemployment Rate vs. Minimum Wage (Top 20 States with Highest Variance)',
    width=500,
    height=400
)

# Show the chart
chart.show()
```

## exclude 2020


```{python}
# Exclude 2020 from the data
filtered_data_no_2020 = filtered_data[filtered_data['Year'] != 2020]

# Create the updated line chart without 2020
chart_no_2020 = alt.Chart(filtered_data_no_2020).mark_line(point=True).encode(
    x=alt.X('Min_Wage:Q', scale=alt.Scale(zero=False), title='Minimum Wage'),
    y=alt.Y('Unemployment_Rate:Q', scale=alt.Scale(zero=False), title='Unemployment Rate'),
    color='State:N',
    tooltip=['State', 'Year', 'Min_Wage', 'Unemployment_Rate']
).properties(
    title='Unemployment Rate vs. Minimum Wage (Excluding 2020)',
    width=800,
    height=400
)

# Show the chart
chart_no_2020.show()

```

### regression 


```{python}
chart_with_regression = alt.Chart(filtered_data_no_2020).mark_circle(size=50, opacity=0.6).encode(
    x=alt.X('Min_Wage:Q', scale=alt.Scale(zero=False), title='Minimum Wage'),
    y=alt.Y('Unemployment_Rate:Q', scale=alt.Scale(zero=False), title='Unemployment Rate'),
    color='State:N',
    tooltip=['State', 'Year', 'Min_Wage', 'Unemployment_Rate']
).properties(
    width=500,
    height=300
) + alt.Chart(filtered_data_no_2020).transform_regression(
    'Min_Wage', 'Unemployment_Rate', method='linear'
).mark_line(color='black').encode(
    x='Min_Wage:Q',
    y='Unemployment_Rate:Q'
).properties(
    title='Unemployment Rate vs. Minimum Wage (Regression Line Included)'
)

# Show the chart
chart_with_regression.show()
```